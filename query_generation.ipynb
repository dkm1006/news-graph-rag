{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing RAG with Neo4j Knowledge Graph\n",
    "\n",
    "\n",
    "Import modules and instantiate connections and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djordje/.virtualenvs/bbuzz24/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "/home/djordje/.virtualenvs/bbuzz24/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "import config\n",
    "from llm import Cortex\n",
    "from ner import EntityFinder\n",
    "from graph import NewsGraphClient\n",
    "\n",
    "\n",
    "snowflake_connection = snowflake.connector.connect(**config.SNOWFLAKE_CONNECTION_PARAMS)\n",
    "model = Cortex(connection=snowflake_connection, model=config.CHAT_MODEL)\n",
    "entity_finder = EntityFinder(config.RELEVANT_LABELS)\n",
    "db = NewsGraphClient()\n",
    "\n",
    "# Define helper functions\n",
    "def map_candidates_to_context(candidates: list[dict[str, str]]) -> str:\n",
    "    context_str = ', '.join(\n",
    "        f\"(:{c['label']} {{ name: '{c['name']}' }}\"\n",
    "        for c in candidates\n",
    "    )\n",
    "    return context_str\n",
    "\n",
    "\n",
    "def map_records_to_context(db_records: list[dict]) -> str:\n",
    "    context_str = ('='*5+'\\n').join(\n",
    "        '/n'.join(f\"{k}: {v}\" for k, v in record.items())\n",
    "        for record in db_records\n",
    "    )\n",
    "    return context_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"Based on the graph schema below, write a Cypher query that answers the user's question. \n",
    "Use only the node labels, relationships and properties provided in the schema:\n",
    "{schema}\n",
    "Entities in the question map to the following database values:\n",
    "{entities_list}\n",
    "\n",
    "Here are some examples: \n",
    "Example 1: For the question \"List 10 titles of articles mentioning Ursula von der Leyen\" and the entity list \"(:Person {{ name: 'Ursula von der Leyen' }}, (:Person {{ name: 'Ursula v. d. Leyn' }}\" the generated Cypher query should be \n",
    "\"MATCH (a:Article)-[:CONTAINS]->(c:Chunk)-[:MENTIONS]->(o:Person) WHERE o.name IN ['Ursula von der Leyen', 'Ursula v. d. Leyn'] RETURN DISTINCT a.title LIMIT 10\"\n",
    "\n",
    "Example 2: For the question \"How many sources mention the EU commission?\" and the entity list \"(:Organization {{ name: 'EU-Kommission' }}\" the generated Cypher query should be \n",
    "\"MATCH (s:Source)-[:PUBLISHED]->(a:Article)-[:CONTAINS]->(c:Chunk)-[:MENTIONS]->(o:Organization) WHERE o.name IN ['EU-Kommission'] WITH DISTINCT s RETURN count(s)\"\n",
    "\n",
    "Example 3: For the question \"News about France and Macron?\" and the entity list \"(:Location {{ name: 'France' }}, (:Person {{ name: 'Emmanuel Macron' }}\" the generated Cypher query should be \n",
    "\"MATCH (c:Chunk)-[:MENTIONS]->(o:Location) WHERE o.name = 'France' UNION MATCH (c:Chunk)-[:MENTIONS]->(o:Person) WHERE o.name = 'Emmanuel Macron' RETURN c.text LIMIT 10\"\n",
    "\n",
    "Question: {question}\n",
    "Cypher query:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Cypher query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'uid': 'Organization:lfpV7XYWRaG6', 'name': 'SPD', 'label': 'Organization', 'score': 3.131917715072632}, {'uid': 'Organization:JkZanoJ8QyOj', 'name': 'SPD-Chefin', 'label': 'Organization', 'score': 2.447997808456421}, {'uid': 'Organization:7Wm84tMGSF-Z', 'name': 'SPD-Politiker', 'label': 'Organization', 'score': 2.447997808456421}]\n",
      "(:Organization { name: 'SPD' }, (:Organization { name: 'SPD-Chefin' }, (:Organization { name: 'SPD-Politiker' }\n"
     ]
    }
   ],
   "source": [
    "question = 'How many articles are there about the SPD?'\n",
    "# Get entities from text\n",
    "mentioned_entities = entity_finder.find(question)\n",
    "# Perform fulltext search\n",
    "candidates = db.lookup_mentioned_entities(mentioned_entities)\n",
    "print(candidates)\n",
    "candidate_context = map_candidates_to_context(candidates)\n",
    "print(candidate_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MATCH (a:Article)-[:CONTAINS]->(c:Chunk)-[:MENTIONS]->(o:Organization) WHERE o.name IN ['SPD', 'SPD-Chefin', 'SPD-Politiker'] WITH DISTINCT a RETURN count(a)\n"
     ]
    }
   ],
   "source": [
    "# Define prompt\n",
    "cypher_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Given an input question, convert it to a Cypher query. No pre-amble.\",),\n",
    "    (\"human\", CYPHER_GENERATION_TEMPLATE),\n",
    "])\n",
    "# Define chain\n",
    "cypher_chain = cypher_prompt | model | StrOutputParser()\n",
    "# Generate Cypher query with found entities\n",
    "generated_query = cypher_chain.invoke({\n",
    "    'question': question,\n",
    "    'entities_list': candidate_context,\n",
    "    'schema': db.graph.schema\n",
    "})\n",
    "print(generated_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform query and generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(a): 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform query\n",
    "response = db.query(generated_query)\n",
    "context = map_records_to_context(response)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt and chain\n",
    "ANSWER_PROMPT_TEMPLATE = (\n",
    "    \"Answer the question below in appropriate detail, given the following context. \"\n",
    "    # \"Think step by step before providing a detailed answer. \"\n",
    "    \"The context was retrieved from the database by the following query:\\n\\n\"\n",
    "    \"Query: {query}\\n\\n\"\n",
    "    \"Context:\\n{context}\\n\\n\"\n",
    "    \"Question: {question}\\n\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "answer_prompt = ChatPromptTemplate.from_template(ANSWER_PROMPT_TEMPLATE)\n",
    "answer_chain = answer_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 8 articles about the SPD.\n"
     ]
    }
   ],
   "source": [
    "# Populate context and generate answer\n",
    "answer = answer_chain.invoke(\n",
    "    {'question': question, 'context': context, 'query': generated_query}\n",
    ")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buzz24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
